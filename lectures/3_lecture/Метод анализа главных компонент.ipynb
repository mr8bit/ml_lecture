{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод анализа главных компонент (Principal Component Analysis, PCA)\n",
    "\n",
    "PCA предназначен для сокращения количества хранимых данных. Предположим, что мы хотим обучить свою модель на данных, в которых есть 200 признаков. Какие-то из этих признаков являются существенными, а какие-то нет. Мы, кончено, можем проанализировать распределение значений в различных признаках, применить эвристическую оценку и т.д., но как гарантированно получить подпространство заданной размерности с наименьшей потерей информации? На этот вопрос как раз и отвечает алгоритм PCA. По сути своей он позволяет построить проецирующий оператор на подпространство заданной размерности, при котором потеря данных будет наименьшей.\n",
    "\n",
    "Алгоритм:\n",
    "\n",
    "- Стандартизация исходных данных\n",
    "\n",
    "- Вычисление матрицы ковариации на стандартизированных данных\n",
    "\n",
    "- Вычисление собственных векторов матрицы ковариации\n",
    "\n",
    "- Выборка n собственных векторов, отвечающих наибольшим собственным значениям, где n - размерность результирующего подпространтва\n",
    "\n",
    "- Получение матрицы проекции на подпространство, базисными векторами которого являются векторы из предыдущего шага\n",
    "\n",
    "Результатом имеем оператор проецирования, который позволяет преобразовывать все входящие данные, уменьшая таким образом их размерность.\n",
    "\n",
    "## Стандартизация исходных данных\n",
    "\n",
    "Вернемся к задаче про вина:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine_dataset = load_wine()\n",
    "\n",
    "# сразу разделим данные на обучающую и тестовую выборки:\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_dataset['data'], wine_dataset['target'], random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы стандартизация наши данные, необходимо по каждому признаку (столбцу) вычислить медиану и дисперсию. Затем вычитаем медиану из каждого признака и делим его на дисперсию (для каждого столбца медиана и дисперсия своя):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# axis = 0 указывает, что вычислять нужно по столбцам\n",
    "\n",
    "μ = X_train.mean(axis=0)\n",
    "σ = X_train.std(axis=0)\n",
    "\n",
    "X_train_normalized = (X_train - μ) / σ\n",
    "\n",
    "# также есть готовый метод\n",
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "\n",
    "print(X_train_normalized == X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление матрицы ковариации на стандартизированных данных\n",
    "\n",
    "Матрица ковариации - это матрица, составленная из попарных ковариаций элементов одного или двух случайных векторов. В нашем случае элементами являются столбцы с признаками, а сама матрица ковариации характеризует связанность этих признаков.\n",
    "\n",
    "Для вычисления матрицы ковариации воспользуемся методом numpy.cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "M_cov = numpy.cov(X_train_normalized.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление собственных векторов матрицы ковариации\n",
    "\n",
    "Для вычисления собственных значений и отвечающих им собственных векторов воспользуемся готовым вызовом numpy.linalg.eig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = numpy.linalg.eig(M_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выборка n собственных векторов, отвечающих наибольшим собственным значениям\n",
    "\n",
    "Сначала упорядочим собственные векторы в порядке невозростания соотвествующих собственных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = numpy.argsort(eigen_values)\n",
    "eigen_values = eigen_values[idx]\n",
    "eigen_vectors = eigen_vectors[:,idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно сделать выборку n векторов с наибольшими собственными значениями и составить из них матрицу с базисом подпространства:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "B = eigen_vectors[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получения матрицы проецирования\n",
    "\n",
    "Проекция вектора/матрицы x на матрицу с базисом M получается следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(M, x):\n",
    "    return ((numpy.linalg.inv(M @ M.T) @ M) @ x.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим функцию, которая возвращает проекцию заданного вектора x при условии, что базис подпространства B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "π = partial(projection, B)\n",
    "\n",
    "def get_new_data(mu, sigma, project, x):\n",
    "    return project((x - mu) / sigma)\n",
    "\n",
    "process = partial(get_new_data, μ, σ, π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение полученной матрицы проекции\n",
    "\n",
    "Теперь преобразуем наши данные в соответсвии с функцией process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовом наборе: 0.71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X_train_processed = process(X_train)\n",
    "X_test_processed = process(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1e4, solver='lbfgs', multi_class='multinomial', max_iter=10000)\n",
    "result = logreg.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Точность на тестовом наборе: {:.2f}\".format(logreg.score(X_test_processed, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также есть встроенный метод для PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовом наборе: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "PCA = decomposition.PCA(n_components=n)\n",
    "X_tr = PCA.fit_transform(X_train)\n",
    "X_ts = PCA.transform(X_test)\n",
    "logreg = LogisticRegression(C=1e4, solver='lbfgs', multi_class='multinomial', max_iter=10000)\n",
    "result = logreg.fit(X_tr, y_train)\n",
    "\n",
    "print(\"Точность на тестовом наборе: {:.2f}\".format(logreg.score(X_ts, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
